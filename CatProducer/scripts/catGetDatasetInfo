#!/usr/bin/env python

import sys, os

gidMap = {
    'v8-0-3':'1456963899', 'v8-0-2':'1895591332', 'v8-0-1':'1981960528', 'v8-0-0':'1203220026',
    'v7-6-6':'183143795',
    'v7-6-1':'1617837617', 'v7-6-2':'1966334211', 'v7-6-3':'266478682', 'v7-6-4':'600658293', 'v7-6-5':'773772766',
    'v7-4-6':'1087889200',
    'v7-4-1':'212761185', 'v7-4-2':'398123591', 'v7-4-3':'512197961', 'v7-4-4':'1038794205', 'v7-4-5':'519625370',
    'v7-3-4':'857222646',
}
gdocbase = "https://docs.google.com/spreadsheets/d/1rWM3AlFKO8IJVaeoQkWZYWwSvicQ1QCXYSzH74QyZqE/pub?gid=%s&single=true&output=csv"

url, era = '', ''
if len(sys.argv) < 2:
    era = sorted(gidMap)[-1]
    gid = gidMap[era]
    print "No argument is given, use latest official production, ", era
    url = gdocbase % gid
elif sys.argv[1] in gidMap:
    era = sys.argv[1]
    gid = gidMap[era]
    url = gdocbase % gid
elif sys.argv[1].beginswith("http"):
    url = sys.argv[1]
    print "Use cutom spreadsheet, ", url
    if len(sys.argv) < 3:
        print "Please give name of this custom era, e.g, v8-0-0a"
        sys.exit(1)
    era = sys.argv[2]
elif sys.argv[1].endswith(".csv") or sys.argv[1].endswith(".txt"):
    path = sys.argv[1]
    print "Use custom csv file in local, ", path
    if len(sys.argv) < 3:
        print "Please give name of this custom era, e.g, v8-0-0a"
        sys.exit(1)
    era = sys.argv[2]

print "Using =",era

from ROOT import *
import csv

if url != '':
    from urllib import urlopen
    print "Retrieving dataset info..."
    print "Source URL =", url
    content = list(csv.reader(urlopen(url).readlines()))
elif path != '' and os.path.exists(path):
    content = list(csv.reader(open(path).readlines()))
else:
    print "!!! input CSV is invalid, ", url, path
    sys.exit(2)

def str2float(x):
    x = x.strip()
    if x == '': return 0.0
    return float(x)
def str2int(x):
    x = x.strip()
    if x == '': return 0
    return int(x)

ds = []
titleBabel = {
    "Name":"name", "Title":"title", "Type":"type",
    "Cross section (pb)":"xsec", "NEvent":"nevt",
    "Avg GenWgt":"avgWgt", "luminosity (fb-1)":"lumi",
    "colour":"colour", "Path":"path",
    "DataSetName":"DataSetName", "options":"options",
}
titleRule = {
    "xsec":str2float, "nevt":str2int, "avgWgt":str2float,
    "lumi":str2float, "colour":(lambda x: eval(x)),
}

## analyze CSV file
titleIdx = {}
for titleCSV in titleBabel:
    titleJSON = titleBabel[titleCSV]
    if titleCSV not in content[0]: continue
    titleIdx[titleJSON] = content[0].index(titleCSV)

for l in content[1:]:
    if len(l) == 0 or len(l[0]) == 0: continue

    item = {}
    for title in titleIdx:
        val = l[titleIdx[title]]
        if title not in titleRule: item[title] = val
        else: item[title] = titleRule[title](val)
    ds.append(item)

## Save results
outDir = os.environ["CMSSW_BASE"]+"/src/CATTools/CatAnalyzer/data"
if not os.path.exists(outDir+"/dataset"): os.makedirs(outDir+"/dataset")

import json
f = open("%s/dataset/dataset.json" % outDir, "w")
print "Saving dataset info to %s/dataset/dataset.json" % outDir
print>>f, json.dumps(ds, indent=4, sort_keys=True)
f.close()

print "Trying to verify file list..."
from CATTools.CatAnalyzer.libxrd import *
cmd, xrdbase = guessxrd()

## A hack to add prefix for the sites
prefix = ""
hostname = os.environ["HOSTNAME"]
if "sdfarm" in hostname:
    prefix = "root://cms-xrdr.sdfarm.kr:1094//"+xrdbase
##

# since all files are at kisti
if not "sdfarm" in hostname:    
    sys.exit()

storageprefix = "/store/group/CAT"
unmatching = []
emptydirectory = []
print "Listing dataset location"
print "-"*80
for d in ds:
    dataSetName = d['DataSetName']
    dataSetName = dataSetName.split('/')
    if len(dataSetName) < 4: continue

    pdName, sdName = dataSetName[1], dataSetName[2]
    path = "%s/%s/%s_%s" % (storageprefix, pdName, era, sdName)
    pathname = ''
    ## #pathnames = map( lambda x: x, listxrd(path)[0] )
    ## pathnames = listxrd(path)[0]
    ## sorted(pathnames)
    ## print pathnames
    tempVersion = 0
    for ll in listxrd(path)[0]:
        currentVersion = int(ll[-13:-7] + ll[-6:])
        if currentVersion > tempVersion:
            tempVersion = currentVersion
            pathname = ll 
    print pathname

    pp = d['path']
    d['files'] = []
    d['size'] = 0
    for dd in listxrd(pp)[0]:
        files, size = listxrd(dd)
        d['size'] += size
        for ff in files:
            if not ff.endswith(".root"): continue
            ff = ff[len(pp)+1:]
            d['files'].append(ff)
    d['path'] = prefix + pp
    d['files'].sort()
    
    f = open("%s/dataset/dataset_%s.txt" % (outDir, d['name']), "w")
    for key in d:
        if key == "files": continue
        print>>f, "#", key, "=", d[key]
    for ff in d['files']:
        print>>f, os.path.join(d['path'], ff)
    f.close()
    if not pathname in pp:
        unmatching.append(pathname)
    if len(d['files']) == 0:
        emptydirectory.append(pdName)
print "-"*80

if len(unmatching) > 0:
    print 'List of datasets not matching with database'
    for i in unmatching:
        print i
    print "-"*80

if len(emptydirectory) > 0:
    print 'List of datasets with no data'
    for i in emptydirectory:
        print i
    print "-"*80
   
print "Saved dataset location info to %s/dataset/dataset_SampleName.txt" % (outDir)
